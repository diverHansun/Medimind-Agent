# MediMind-Agent 技术架构与演进路线

> 版本：v1.0  
> 当前状态：多类型文档 RAG Agent（通用知识检索）  
> 演进目标：专业化医疗健康问答 Agent

## 1. 项目定位与演进路线

### 当前阶段：通用多类型文档 RAG Agent
- **核心能力**：基于 LlamaIndex + ZhipuAI 的多格式文档检索与问答
- **支持格式**：TXT、PDF、CSV、Markdown、Excel（.xlsx/.xls）
- **技术栈**：LlamaIndex RAG + ZhipuAI GLM-4.5 + FAISS 向量检索
- **应用场景**：通用知识库问答、文档检索、信息提取

### 演进目标：专业化医疗健康 Agent
- **愿景**：构建专注医疗健康问答与知识检索的智能体，提供循证医学信息与通俗易懂的解释
- **目标领域**：
  - 常见临床与公众健康主题（疾病诊疗、用药、康复、预防、科普）
  - 面向中文为主、兼顾中英混合输入
  - 通过 RAG + 微调（LoRA）兼顾实时性与专业性
  - 明确安全合规边界：不做诊断、处方与紧急医疗指导的替代

## 2. 当前技术架构

### 2.1 核心技术栈
- **LLM**：ZhipuAI GLM-4.5（智谱 AI）
- **Embedding**：ZhipuAI Embedding-3（1024维）
- **RAG 框架**：LlamaIndex（文档加载、索引、检索、生成）
- **向量存储**：FAISS（本地持久化）
- **配置管理**：YAML + 环境变量（优先级：函数参数 > 环境变量 > YAML > 默认值）

### 2.2 模块化架构
```
src/
├── common/           # 通用配置与工具
│   └── config.py     # 配置管理（LLM、Embedding、RAG参数）
├── llm/              # LLM 适配层
│   └── zhipu.py      # ZhipuAI LLM 封装
├── rag/              # RAG 核心模块
│   ├── embeddings/   # 向量模型
│   ├── document_loader/  # 文档加载器
│   ├── text_splitter/    # 文本分割
│   ├── indexing/         # 索引构建与管理
│   ├── retrieval/        # 检索策略
│   ├── generation/       # 查询引擎
│   └── postprocessors/   # 后处理器
└── agent/            # Agent 组合层
    └── agent.py      # 统一接口
```

### 2.3 数据组织
```
data/
├── documents/        # 原始文档（按类型分类）
│   ├── txt/         # 文本文件
│   ├── pdf/         # PDF 文档
│   ├── csv/         # CSV 数据
│   ├── md/          # Markdown 文档
│   └── excel/       # Excel 文件
└── indexes/         # 向量索引
    └── zhipu/       # ZhipuAI 索引
```

## 3. 医疗专业化演进路线

### 3.1 当前通用能力
- 多格式文档加载与处理
- 基于语义的文档检索
- 可配置的 LLM 参数
- 模块化的 RAG 流水线

### 3.2 医疗专业化目标
- **模型**：智谱 AI LLM（GLM 系列）作为推理核心；在智谱平台进行 LoRA 微调以适配医疗 QA 风格与格式
- **数据**：使用公开医学 QA 数据集（PubMedQA、MedDialog）+ 知识库（医学指南、权威科普、FAQ、PubMed 摘要）
- **框架**：LlamaIndex 作为 RAG 基座（索引、检索、路由、后处理）
- **向量检索**：FAISS（facebookresearch/faiss）
- **组合**：RAG 先覆盖广度与实时性；LoRA 微调补齐风格、格式与意图理解

## 4. 医疗专业化约束与安全

### 4.1 合规边界
- 提醒"非医疗执业建议"，引导就医；对高风险场景（胸痛、卒中、过敏反应等）优先触发"紧急就医"建议
- 隐私合规：避免收集可识别个人信息（PII/PHI）；数据最小化与脱敏存储；日志审计与访问控制
- 来源透明：提供引用/出处（医学指南、权威期刊、PubMed 摘要等）

### 4.2 安全策略
- 提示词安全：拒绝不当医疗要求（越权诊断、违规处方、虚假证明等）；对不确定结论强化"需线下就医"
- 过滤与红线：毒品制备、假药制作、误导性偏方等直接拒绝
- 事实一致性：对关键结论进行基于检索证据的自检（如"无证据则弱化结论并给出继续就医建议"）

## 5. 医疗专业化数据资产

### 5.1 开放数据集
- **PubMedQA**：基于 PubMed 文章的医学问答
- **MedDialog（zh/en）**：医患对话数据集，覆盖多科室场景

### 5.2 知识来源
- **医学指南**：心血管、糖尿病、肿瘤等权威学会指南
- **科普文章**：国家卫健委、三甲医院科普、WHO/CDC 等权威机构
- **医疗 FAQ**：医院/医保/药监常见问答
- **PubMed 论文摘要**：覆盖更新与争议点

### 5.3 数据清洗策略
- 去重、去噪、格式标准化（Markdown/结构化 JSON）
- 正负样本标注与无关内容剔除（广告、行医个人经历、低质偏方）
- 中文分句、术语标准化（UMLS/中医术语可择机扩展）
- PII/PHI 脱敏；版权合规（保留链接与出处元数据）

## 6. 医疗专业化训练与微调

### 6.1 LoRA 微调目标
- 学习医疗 QA 的话术、结构化回答（摘要-证据-建议-告知）
- 拒答与风险提示模板
- 输入格式示例（指令微调）：
  - instruction：用户问题（含上下文与约束）
  - input：检索到的证据片段（可空）
  - output：参考答案（包含来源标注、限制提示、就医建议）

### 6.2 数据来源
- PubMedQA/MedDialog 清洗后的指令样本
- 合成模板样本（覆盖拒答、安全提示、出处引用、三段式结构）

### 6.3 评估策略
- 切分出未参与训练的开发/验证/测试集
- 覆盖常见病种与安全边界用例

## 7. 当前 RAG 架构实现

### 7.1 文档处理流水线
- **文档加载器**：支持 TXT、PDF、CSV、Markdown、Excel 多格式
- **文档切分**：200-600 字/块，基于语义边界（标题/段落/句子）与规则结合
- **元数据管理**：来源、时间、作者/机构、学科、证据等级、URL、版权、语种

### 7.2 向量化与存储
- **Embeddings**：ZhipuAI Embedding-3（1024维）
- **向量库**：FAISS 本地持久化，支持索引版本管理
- **存储策略**：按语种/学科分库或分索引

### 7.3 检索与生成
- **检索策略**：语义检索（kNN）+ 词法过滤 + 时间衰减
- **QueryEngine**：Retriever -> Node postprocessor -> LLM 生成
- **输出结构**：
  - 标题/摘要
  - 关键要点
  - 建议与限制
  - 引用与链接

### 7.4 医疗专业化增强（规划）
- **事实自检**：简单一致性检查（关键结论必须出现在证据片段中）
- **置信度管理**：低置信度时提示"需要进一步就医/查询权威指南"
- **重排序**：可选 rerank 与 HyDE/查询扩展

## 8. 技术集成要点

### 8.1 环境与依赖
- **Python 版本**：3.10+
- **核心依赖**：`llama-index`、`faiss-cpu`（或 `faiss-gpu`）、`pydantic`、`tiktoken`
- **API 密钥**：`ZHIPUAI_API_KEY`（通过 .env 管理）

### 8.2 当前实现状态
- **LLM 集成**：ZhipuAI GLM-4.5，支持可配置参数（temperature、max_tokens、top_p、system_prompt）
- **Embedding 集成**：ZhipuAI Embedding-3（1024维）
- **向量索引**：FAISS 本地持久化，支持索引构建与加载
- **配置管理**：YAML 配置文件 + 环境变量覆盖

### 8.3 医疗专业化集成（规划）
- **LLM 微调**：智谱平台 LoRA 微调，适配医疗 QA 风格
- **多模型支持**：BioBERT 增强检索（与 ZhipuAI 混合）
- **高级检索**：重排序、查询扩展、时间衰减

## 9. 评测与验收策略

### 9.1 当前通用 RAG 评测
- **检索质量**：Recall@k、nDCG、覆盖率、重复率
- **生成质量**：事实一致性、可读性与结构化程度
- **性能指标**：首 token 延迟、整体时延、吞吐、缓存命中率

### 9.2 医疗专业化评测（规划）
- **医学正确率**：专家抽检、事实一致性（基于证据匹配）
- **安全评估**：不当回答触发率（越界诊断/处方/危险行为）、拒答恰当率
- **基准数据**：
  - PubMedQA/MedDialog 留出测试集
  - 自建专业与安全边界集（心梗、卒中、孕产、儿科用药等高风险场景）
- **评测流程**：离线评测 + 线上 A/B（灰度），专家抽样复核

## 10. 交互与体验设计

### 10.1 当前通用交互
- **多轮对话**：支持上下文记忆（会话级 RAG，可限制轮次/窗口）
- **来源展示**：明确展示来源与时间；过期内容告警
- **结构化回答**：摘要/要点/建议/引用

### 10.2 医疗专业化交互（规划）
- **高风险触发器**：识别危险症状，提醒线下就医与急救指引
- **安全边界**：明确拒答边界案例（诊断代码、处方剂量、侵入性操作指导）
- **证据不足处理**：鼓励进一步就医/给出权威渠道链接

## 11. 部署与运维策略

### 11.1 当前部署架构
- **本地部署**：单机 RAG 服务 + ZhipuAI API 调用
- **监控指标**：检索质量、生成质量、API 调用成功率、响应时间
- **数据管理**：索引版本控制、文档更新、配置管理

### 11.2 医疗专业化部署（规划）
- **架构升级**：API 网关（鉴权/限流）+ RAG 服务 + LLM 服务代理 + 向量库 + 监控/日志
- **数据治理**：
  - 内容更新节奏（月/双周）；指南/论文订阅更新
  - 版权合规与来源日志留存
- **灰度与回滚**：新索引/新提示/新 LoRA 逐步放量；异常时快速回滚

## 12. 资源与成本估算

### 12.1 当前成本
- **模型推理**：按 QPS 与上下文窗口估算 API 成本
- **向量库**：每 100 万段文本（~300 字/段）约占用数 GB 级存储
- **存储**：本地 FAISS 索引，成本较低

### 12.2 医疗专业化成本（规划）
- **训练成本**：LoRA 微调视样本量（1-5 万）与迭代次数
- **多模型支持**：BioBERT 等额外模型的计算成本
- **高级检索**：重排序、查询扩展的额外计算开销

## 13. 风险清单与应对

### 13.1 当前通用风险
- **数据质量**：建立数据评分与抽检流程；对低质来源降权或剔除
- **幻觉与误导**：强化基于证据的生成模板；低置信度时明确提示

### 13.2 医疗专业化风险（规划）
- **知识时效性**：高频更新学科（传染病、肿瘤）加大订阅更新与时间衰减权重
- **合规风险**：在显著位置放置免责声明；内置拒答策略与敏感词过滤

## 14. 开发里程碑

### 14.1 已完成（当前状态）
- **M0**：通用多类型文档 RAG Agent 基础架构
  - LlamaIndex + ZhipuAI 集成
  - 多格式文档支持（TXT、PDF、CSV、MD、Excel）
  - 模块化架构与配置管理
  - FAISS 向量索引与持久化

### 14.2 医疗专业化里程碑（规划）
- **M1（第 1-2 周）**：医疗知识库构建与安全拒答模板
- **M2（第 3-5 周）**：知识库规模化，Embeddings 与检索调优，评测基线
- **M3（第 6-8 周）**：LoRA 微调（风格与结构化输出），上线灰度，专家复核闭环
- **M4（第 9-12 周）**：安全与合规模块完善，多轮对话与会话级 RAG，监控与成本优化

## 15. 开发实施清单

### 15.1 已完成实施（当前状态）
- **环境与依赖**：
  - Python 3.10+ 环境配置
  - 核心依赖：`llama-index`、`faiss-cpu`、`pydantic`、`tiktoken`
  - API 密钥管理：`.env` 文件配置 `ZHIPUAI_API_KEY`
- **核心模块实现**：
  - **数据接入与清洗**：多格式文档加载器（TXT、PDF、CSV、MD、Excel）
  - **向量化与索引**：ZhipuAI Embedding-3 + FAISS 持久化
  - **检索与组装**：LlamaIndex QueryEngine + 后处理器
  - **配置管理**：YAML 配置文件 + 环境变量优先级
  - **模块化架构**：清晰的代码组织结构

### 15.2 医疗专业化实施（规划）
- **安全与合规**：拒答策略、敏感检测、紧急就医建议、日志与审计
- **评测与监控**：离线评测集、线上指标、异常告警
- **高级功能**：LoRA 微调、多模型支持、重排序、查询扩展

## 16. 当前项目结构

### 16.1 已实现目录结构
```
MediMind-Agent/
├─ src/                   # 源码模块
│  ├─ common/             # 通用配置与工具
│  │  └─ config.py        # 配置管理（LLM、Embedding、RAG参数）
│  ├─ llm/                # LLM 适配层
│  │  └─ zhipu.py         # ZhipuAI LLM 封装
│  ├─ rag/                # RAG 核心模块
│  │  ├─ embeddings/      # 向量模型
│  │  │  └─ zhipu.py      # ZhipuAI Embedding-3
│  │  ├─ document_loader/ # 文档加载器
│  │  │  └─ loader.py     # 多格式文档加载
│  │  ├─ text_splitter/   # 文本分割
│  │  │  └─ splitter.py   # 文档切分策略
│  │  ├─ indexing/        # 索引构建与管理
│  │  │  └─ builder.py    # FAISS 索引构建
│  │  ├─ retrieval/       # 检索策略
│  │  │  └─ retriever.py  # 检索器实现
│  │  ├─ generation/      # 查询引擎
│  │  │  └─ query_engine.py # LlamaIndex QueryEngine
│  │  └─ postprocessors/  # 后处理器
│  │     └─ processors.py # 节点后处理
│  └─ agent/              # Agent 组合层
│     └─ agent.py         # 统一接口
├─ main.py                # 项目入口
├─ data/                  # 数据目录
│  ├─ documents/          # 原始文档（按类型分类）
│  │  ├─ txt/            # 文本文件
│  │  ├─ pdf/            # PDF 文档
│  │  ├─ csv/            # CSV 数据
│  │  ├─ md/             # Markdown 文档
│  │  └─ excel/          # Excel 文件
│  └─ indexes/           # 向量索引
│     └─ zhipu/          # ZhipuAI 索引
├─ configs/              # 配置文件
│  ├─ llm.yaml           # LLM 参数配置
│  ├─ embeddings.yaml    # Embedding 配置
│  └─ rag.yaml           # RAG 参数配置
├─ scripts/              # 维护脚本
│  └─ rebuild_index.py   # 索引重建脚本
├─ docs/                 # 文档
├─ .env.example          # 环境变量模板
└─ requirements.txt      # 依赖列表
```

### 16.2 医疗专业化扩展（规划）
- **新增模块**：`src/rag/embeddings/biobert.py`（BioBERT 支持）
- **安全模块**：`src/safety/`（拒答策略、敏感检测）
- **评测模块**：`eval/`（评测脚本与样本）
- **监控模块**：`monitoring/`（日志、指标、告警）

## 17. 技术集成要点

### 17.1 当前实现状态
- **LLM**：`ZhipuAI(model="glm-4.5", temperature=0.2, max_tokens=4096)`
- **Embedding**：`ZhipuAIEmbedding(model="embedding-3")`（1024维）
- **向量库**：`FaissVectorStore` + `VectorStoreIndex`（维度匹配）
- **QueryEngine**：Retriever -> Postprocessors -> LLM（输出模板注入 + 引用拼接）

### 17.2 配置管理
- **优先级**：函数参数 > 环境变量 > YAML 配置 > 默认值
- **LLM 配置**：`configs/llm.yaml`（model、temperature、max_tokens、top_p、system_prompt）
- **Embedding 配置**：`configs/embeddings.yaml`（model、dimension、index_dir）
- **RAG 配置**：`configs/rag.yaml`（top_k、min_relevance、filters）

### 17.3 医疗专业化集成（规划）
- **多模型支持**：BioBERT + ZhipuAI 混合检索
- **高级检索**：重排序、查询扩展、时间衰减
- **安全策略**：拒答策略、敏感检测、紧急就医建议

## 18. 项目总结

### 18.1 当前成就
- **基础架构完成**：模块化的 RAG Agent 架构，支持多格式文档处理
- **技术栈集成**：LlamaIndex + ZhipuAI + FAISS 完整集成
- **配置管理**：灵活的 YAML + 环境变量配置系统
- **代码质量**：清晰的模块化设计，易于扩展和维护

### 18.2 演进方向
- **专业化路径**：从通用 RAG Agent 向医疗健康专业 Agent 演进
- **技术增强**：LoRA 微调、多模型支持、高级检索策略
- **安全合规**：医疗安全边界、合规性检查、风险控制
- **用户体验**：结构化回答、来源引用、风险提示

### 18.3 技术优势
- **模块化设计**：各组件独立，易于测试和扩展
- **配置驱动**：通过配置文件灵活调整系统行为
- **多格式支持**：支持主流文档格式，适应不同数据源
- **可扩展性**：为医疗专业化预留了充分的扩展空间
